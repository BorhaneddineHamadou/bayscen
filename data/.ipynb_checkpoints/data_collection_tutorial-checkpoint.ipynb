{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayScen Data Collection and Processing Tutorial\n",
    "\n",
    "This notebook demonstrates how to collect and process weather data for BayScen scenario generation.\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Data Sources:**\n",
    "\n",
    "**Frost API** (Norwegian Meteorological Institute)\n",
    "- Official documentation: https://frost.met.no/\n",
    "- Credentials: https://frost.met.no/auth/requestCredentials.html\n",
    "- **Main Station**: Road conditions (friction, wetness, surface type), wind speed, precipitation, visibility\n",
    "- **Secondary Station**: Cloudiness data (since main station may lack it)\n",
    "\n",
    "**Output:** Hourly weather data with 9 parameters ready for Bayesian Network training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Configuration\n",
    "\n",
    "First, set up your API credentials and data collection parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Credentials\n",
    "# Register at: https://frost.met.no/auth/requestCredentials.html\n",
    "FROST_CLIENT_ID = \"YOUR_CLIENT_ID\"\n",
    "FROST_CLIENT_SECRET = \"YOUR_CLIENT_SECRET\"\n",
    "\n",
    "# Location and stations\n",
    "STATION_MAIN = \"SN84770\"  # Main station with road conditions\n",
    "STATION_CLOUD = \"SN90450\"  # Station with cloudiness data\n",
    "\n",
    "# Time period\n",
    "START_TIME = \"2020-12-01T00:00:00Z\"\n",
    "END_TIME = \"2024-03-03T23:59:59Z\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Collect Raw Data\n",
    "\n",
    "Fetch data from all sources and save to `raw/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collect import collect_full_dataset\n",
    "\n",
    "# Collect data\n",
    "output_files = collect_full_dataset(\n",
    "    frost_client_id=FROST_CLIENT_ID,\n",
    "    frost_client_secret=FROST_CLIENT_SECRET,\n",
    "    station_id_main=STATION_MAIN,\n",
    "    station_id_cloud=STATION_CLOUD,\n",
    "    start_time=START_TIME,\n",
    "    end_time=END_TIME,\n",
    "    output_dir=Path(\"raw\")\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Raw data collection complete!\")\n",
    "for name, path in output_files.items():\n",
    "    print(f\"  {name}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Raw Data\n",
    "\n",
    "Load the collected raw data for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load main station data\n",
    "df_main = pd.read_csv(\"raw/frost_main_station.csv\")\n",
    "df_main['timestamp'] = pd.to_datetime(df_main['timestamp'], utc=True)\n",
    "\n",
    "print(f\"Main station data: {df_main.shape}\")\n",
    "print(f\"Columns: {list(df_main.columns)}\")\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cloudiness data (if available)\n",
    "df_cloud = None\n",
    "cloud_file = Path(\"raw/frost_cloud_station.csv\")\n",
    "\n",
    "if cloud_file.exists():\n",
    "    df_cloud = pd.read_csv(cloud_file)\n",
    "    df_cloud['timestamp'] = pd.to_datetime(df_cloud['timestamp'], utc=True)\n",
    "    print(f\"Cloud station data: {df_cloud.shape}\")\n",
    "    display(df_cloud.head())\n",
    "else:\n",
    "    print(\"No cloudiness data from secondary station\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Process Data\n",
    "\n",
    "Transform raw data into BayScen format with:\n",
    "- Hourly aggregation\n",
    "- Missing value handling\n",
    "- Discretization to CARLA-compatible ranges\n",
    "- Final column naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import WeatherDataProcessor\n",
    "\n",
    "# Initialize processor\n",
    "processor = WeatherDataProcessor()\n",
    "\n",
    "# Run full processing pipeline\n",
    "df_processed = processor.process_full_pipeline(df_main, df_cloud)\n",
    "\n",
    "print(\"\\n✓ Processing complete!\")\n",
    "print(f\"Final shape: {df_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Inspect Processed Data\n",
    "\n",
    "View the final dataset structure and distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df_processed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data types and null counts\n",
    "print(\"Data Types:\")\n",
    "print(df_processed.dtypes)\n",
    "print(\"\\nNull Values:\")\n",
    "print(df_processed.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display value distributions\n",
    "for col in df_processed.columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df_processed[col].value_counts().sort_index().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Save Processed Data\n",
    "\n",
    "Save the final dataset for use in BayScen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"processed\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save processed data\n",
    "output_file = output_dir / \"bayscen_final_data.csv\"\n",
    "df_processed.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✓ Saved: {output_file}\")\n",
    "print(f\"  {len(df_processed)} rows × {len(df_processed.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You now have:\n",
    "\n",
    "1. **Raw data** in `raw/` directory\n",
    "   - `frost_main_station.csv` - Road conditions, wind, precipitation, visibility\n",
    "   - `frost_cloud_station.csv` - Cloudiness data\n",
    "\n",
    "2. **Processed data** in `processed/` directory\n",
    "   - `bayscen_final_data.csv` - Ready for Bayesian Network training\n",
    "\n",
    "**Next steps:**\n",
    "- Use the processed data to train Bayesian Networks\n",
    "- Generate test scenarios with BayScen\n",
    "- Validate scenarios in CARLA simulation\n",
    "\n",
    "**Final column format:**\n",
    "- `Time of Day` - Sun altitude angle (-90 to 90)\n",
    "- `Cloudiness` - Cloud coverage (0-100)\n",
    "- `Precipitation` - Precipitation intensity (0-100)\n",
    "- `Wind Intensity` - Wind strength (0-100)\n",
    "- `Fog Density` - Fog thickness (0-100)\n",
    "- `Fog Distance` - Visibility distance (0-100)\n",
    "- `Wetness` - Road wetness (0-100)\n",
    "- `Precipitation Deposits` - Water/snow on road (0-100)\n",
    "- `Road Friction` - Tire grip (0.0-1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
