{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayScen Evaluation - Paper Results Replication\n",
    "\n",
    "This notebook evaluates BayScen and baseline methods, generating all tables from the paper:\n",
    "- **Table II:** Safety-Critical Scenario Discovery (Effectiveness)\n",
    "- **Table III:** Realism Analysis\n",
    "- **Table IV:** 3-Way Coverage Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from metrics import (\n",
    "    evaluate_all_methods,\n",
    "    generate_table_ii,\n",
    "    generate_table_iii,\n",
    "    generate_table_iv,\n",
    "    save_paper_tables\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose scenario\n",
    "SCENARIO = 1  # 1 or 2\n",
    "\n",
    "# Define paths\n",
    "scenario_folder = Path(f\"Scenario{SCENARIO} Generated Scenarios\")\n",
    "json_folder = Path(f\"Scenario{SCENARIO} Execution Results (JSON)\")\n",
    "real_data_path = Path(\"../data/bayscen.csv\")\n",
    "\n",
    "# Methods to evaluate\n",
    "methods = ['bayscen', 'random', 'sitcov', 'PICT_3w', 'PICT_2w', 'CTBC']\n",
    "\n",
    "print(f\"Evaluating Scenario {SCENARIO}\")\n",
    "print(f\"Methods: {', '.join(methods)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Attributes and Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCENARIO == 1:\n",
    "    attributes = [\n",
    "        'Cloudiness', 'WindIntensity', 'Precipitation', 'PrecipitationDeposits',\n",
    "        'Wetness', 'FogDensity', 'RoadFriction', 'FogDistance'\n",
    "    ]\n",
    "    parameter_domains = {\n",
    "        'Cloudiness': [0, 20, 40, 60, 80, 100],\n",
    "        'WindIntensity': [0, 20, 40, 60, 80, 100],\n",
    "        'Precipitation': [0, 20, 40, 60, 80, 100],\n",
    "        'PrecipitationDeposits': [0, 20, 40, 60, 80, 100],\n",
    "        'Wetness': [0, 20, 40, 60, 80, 100],\n",
    "        'RoadFriction': [0.1, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "        'FogDensity': [0, 20, 40, 60, 80, 100],\n",
    "        'FogDistance': [0, 20, 40, 60, 80, 100]\n",
    "    }\n",
    "else:  # Scenario 2\n",
    "    attributes = [\n",
    "        'TimeOfDay', 'Cloudiness', 'WindIntensity', 'Precipitation',\n",
    "        'PrecipitationDeposits', 'Wetness', 'FogDensity',\n",
    "        'RoadFriction', 'FogDistance'\n",
    "    ]\n",
    "    parameter_domains = {\n",
    "        'TimeOfDay': [-90, -60, -30, 0, 30, 60, 90],\n",
    "        'Cloudiness': [0, 20, 40, 60, 80, 100],\n",
    "        'WindIntensity': [0, 20, 40, 60, 80, 100],\n",
    "        'Precipitation': [0, 20, 40, 60, 80, 100],\n",
    "        'PrecipitationDeposits': [0, 20, 40, 60, 80, 100],\n",
    "        'Wetness': [0, 20, 40, 60, 80, 100],\n",
    "        'RoadFriction': [0.1, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "        'FogDensity': [0, 20, 40, 60, 80, 100],\n",
    "        'FogDistance': [0, 20, 40, 60, 80, 100]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluation (2-3 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all methods\n",
    "results = evaluate_all_methods(\n",
    "    scenario_folder=scenario_folder,\n",
    "    json_folder=json_folder,\n",
    "    real_data_path=real_data_path,\n",
    "    methods=methods,\n",
    "    attributes=attributes,\n",
    "    parameter_domains=parameter_domains,\n",
    "    output_file=Path(f\"results_scenario{SCENARIO}.csv\")\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table II: Safety-Critical Scenario Discovery (RQ1: Effectiveness)\n",
    "\n",
    "Reports both absolute counts and normalized rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_ii = generate_table_ii(results)\n",
    "table_ii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table III: Realism Analysis of Discovered Safety-Critical Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_iii = generate_table_iii(results)\n",
    "table_iii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table IV: 3-Way Coverage Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_iv = generate_table_iv(results)\n",
    "table_iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save All Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all paper tables to CSV\n",
    "save_paper_tables(results, output_prefix=f\"paper_scenario{SCENARIO}\")\n",
    "\n",
    "print(\"\\n✓ All tables saved!\")\n",
    "print(f\"  - paper_scenario{SCENARIO}_II_effectiveness.csv\")\n",
    "print(f\"  - paper_scenario{SCENARIO}_III_realism.csv\")\n",
    "print(f\"  - paper_scenario{SCENARIO}_IV_coverage.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export LaTeX (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LaTeX format for paper\n",
    "print(\"LaTeX Table II:\")\n",
    "print(table_ii.to_latex(index=False))\n",
    "\n",
    "print(\"\\nLaTeX Table III:\")\n",
    "print(table_iii.to_latex(index=False))\n",
    "\n",
    "print(\"\\nLaTeX Table IV:\")\n",
    "print(table_iv.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✓ All paper tables replicated successfully!\n",
    "\n",
    "The CSV files are ready for:\n",
    "- Direct inclusion in spreadsheet software\n",
    "- Further analysis\n",
    "- Comparison across scenarios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
